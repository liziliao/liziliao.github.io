<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta content="IE=edge" http-equiv="X-UA-Compatible">
	<meta content="width=840, initial-scale=1.0" name="viewport">
	<meta content="Lizi Liao" name="author">
	<meta content="Homepage" name="description">

	<title>Lizi Liao - SMU - SCIS</title>
	<link rel="shortcut icon" href="https://www.ic.gatech.edu/sites/all/themes/coc_sub_theme/favicon.ico" type="image/vnd.microsoft.icon">
	<!-- Bootstrap core CSS -->
	<link href="./files/bootstrap.min.css" rel="stylesheet">
	<!-- Bootstrap theme -->
	<link href="./files/bootstrap-theme.min.css" rel="stylesheet">
	<!-- Bootstrap icon -->
	<link href="./files/bootstrap.icon-large.min.css" rel="stylesheet">
	<!-- Custom styles for this template -->
	<link href="./files/theme.css" rel="stylesheet">
	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<link rel="stylesheet" href="./files/font-awesome.min.css">

	<!--[if lt IE 9]>
	  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
	  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
	<![endif]-->
<script src="chrome-extension://njgehaondchbmjmajphnhlojfnbfokng/js/contentScripts/dom.js"></script></head>

<body>
   <script type="text/javascript" async="" src="./files/ga.js"></script>
	<div class="container-narrow">
		<div class="title">

			<h4><strong>Lizi Liao</strong> &nbsp;&nbsp;&nbsp;&nbsp; 
			
			<img class="img-thumbnail-lizi" height="300" hspace="10" src="./files/lizi_profile_image.png" style="float:right"> 
			
			</h4>
			Assistant Professor<br>
			<a href="https://scis.smu.edu.sg/">School of Computing and Information Systems</a> <br>
			<a href="https://www.smu.edu.sg/">Singapore Management University</a><br>
			<span class="glyphicon glyphicon-envelope"></span>&nbsp; <tt>lzliao at smu dot edu dot sg</tt><br>
			<b>Office: </b>SCIS2-4056<br>
			<a href="https://scholar.google.com.sg/citations?user=W2b08EUAAAAJ&hl=en">[Google Scholar]</a>

		    <br><br>
		    I am a faculty member of the <a href="https://scis.smu.edu.sg/">School of Computing and Information Systems</a> at <a href="https://www.smu.edu.sg/">SMU</a>. My research explores two questions: What are the underlying principles of humans understanding conversation context as well as making proper responses, and how we can implement them on machine learning models? Research on this topic has to necessarily be at the intersection of Machine Learning, Natural Language Processing and Multimedia. In my lab, we are specifically interested in task-oriented dialogues, proactive conversational agents, and multimodal conversational search and recomendation as the application target. I received my Ph.D. from National University of Singapore, advised by Professor <a href="https://scholar.google.com.sg/citations?user=Z9DWCBEAAAAJ&hl=zh-CN">Tat-Seng Chua</a>.
		    
		    <br>
			<br>
						
			<img src="./files/recruitment.png" width="20" alt="" style="border-style: none" align="center"> &nbsp; I'm recruiting 0-2 new PhD students every year (apply to <a href="https://scis.smu.edu.sg/phd/online-application">PhD</a> program and list me as a potential advisor). Our group also has multiple positions for summer interns and visiting research students. Please feel free to email me with your CV if you are interested. <br> 
			

		</div>

<div class="navbar navbar-default" role="navigation">
		
   		<div class="container">
        
				<div class="navbar-collapse">
				<ul class="nav navbar-nav">
					<li>
						<a href="https://liziliao.github.io/#research">Research</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#publications">Publications</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#teach">Teaching</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#publications">Code &amp; Data</a>
					</li>
				</ul>

          
			</div>
		
		</div>
		</div>


		<div class="content">
			<h5 class="text-primary" id="news">What's New</h5>
		         
			<!-- <ul class="news"> -->
			<ul>
				<li style="list-style: none"><br>
				</li>

			<!-- <ul class="news"> -->
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jan 2024], received the <a href="https://research.google/outreach/featured-research-collaborations/"> Google South Asia & Southeast Asia research awards 2023</a>. </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Dec 2023], two papers accepted to AAAI 2024: (1) <a href="./papers/RTCP.pdf"> sentiment quadruple extraction in dialogues</a>; (2) <a href="./papers/proactive_prompt.pdf">dialogue commonsense inference</a>. </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Nov 2023], invited to attend the <a href="https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/24352"> Dagstuhl Perspectives Workshop</a> on Conversational Agents: A Framework for Evaluation (CAFE). </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Oct 2023], 4 papers accepted to EMNLP 2023: (1) <a href="./papers/RTCP.pdf"> target-driven conversation promotion</a>; (2) <a href="./papers/proactive_prompt.pdf">proactive dialogue systems</a>; (3) ClusterPrompt - <a href="./papers/clusterprompt.pdf" >new intent discovery</a>; (4) <a href="./papers/emnlp23_survey.pdf"> survey on task-oriented dialogues</a>. </li>
		   <li><b style="color: green; background-color: #ffff42">NEW</b> [Sep 2023], invited to serve as Doctoral Consortium Chair in <a href="https://sigir-2024.github.io/">SIGIR 2024</a>. </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Aug 2023], check out our new ECML/PKDD 2023 paper on <a href="https://arxiv.org/abs/2307.00968">active learning</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Aug 2023], talk at FPT Software AI Residency – AI Center.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Aug 2023], invited to be a mentor at the <a href="https://recsys.acm.org/recsys23/"> RecSys 2023</a> Doctoral Symposium.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jul 2023], two papers accepted to ACM Multimedia 2023: (1) <a href="https://arxiv.org/pdf/2308.04502.pdf">conversational multimodal emotion recognition</a>; (2) <a href="./papers/ACM_MM_2023_Weakly_VMR.pdf">iterative video moment retrieval</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jul 2023], check out our new ACL 2023 paper on <a href="https://aclanthology.org/2023.findings-acl.849.pdf">conversational aspect-based sentiment quadruple analysis</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [May 2023], give tutorial at SIGIR 2023 with <a href="https://infosense.cs.georgetown.edu/grace/">Grace </a> and <a href="https://ischool.uw.edu/people/faculty/profile/chirags">Chirag</a> on <a href="https://dl.acm.org/doi/abs/10.1145/3539618.3594250">Proactive Conversational Agents in the Post-ChatGPT World</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Apr 2023], invited to serve as Local Arrangements Chair in <a href="https://www2024.thewebconf.org/">The Web Conference 2024</a> (known as WWW). 
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Mar 2023], invited to serve as	Area Chair for the Dialogue Systems track at <a href="http://tcci.ccf.org.cn/conference/2023/">NLPCC 2023</a>.
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Mar 2023], talk at Nanyang Technological University.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Feb 2023], give tutorial at WSDM 2023 on <a href="https://liziliao.github.io/papers/WSDM2023_Tutorial.pdf">Proactive Conversational Agents</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Oct 2022], 3 papers accepted to EMNLP 2022: (1) <a href="https://liziliao.github.io/papers/Conversation_Disentanglement.pdf">conversation disentanglement</a>; (2) <a href="https://liziliao.github.io/papers/User_Simulation.pdf">dialogue user simulator</a>; (3) <a href="https://liziliao.github.io/papers/Semi_supervised.pdf">semi-supervised new slot discovery</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jul 2022], the undergraduate student <a href="https://yecchen.github.io/">Chenchen Ye</a> co-supervised by me win the <a href="https://www.comp.nus.edu.sg/news/2022-ourp-ocp-2122/">Outstanding Undergraduate Researcher</a> prize in NUS!</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jul 2022], invited to serve as Finance and Registration Chair in <a href="https://www.wsdm-conference.org/2023/">WSDM 2023</a>. </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jul 2022], invited to chair a session in SIGIR 2022. </li>
			<!--
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jun 2021], paper on <a href="https://liziliao.github.io/papers/Ref2022.pdf">multimodal conversational response generation</a> is accepted at ACM Multimedia 2022. </li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Mar 2021], check out our SIGIR 2022 paper on <a href="https://liziliao.github.io/papers/Str2022.pdf">structured and natural responses co-generation</a>. </li>
			-->
			</ul>		
		</div>




		<div class="content">
			<h5 class="text-primary" id="research">Research Highlights</h5> 
			

			<div class="projects" style="margin-left: 1em; margin-right: 1em">
				<div class="boxed">
					<p><a href="./files/pic_proactive.png"><img border="1px" hspace="10" vspace="10" src="./files/pic_proactive.png" style="float: right;" width="330px"></a>
					</p>

<h5><strong>Proactive Conversational AI</strong>
					</h5>


<p> We recently published one of the earliest works on developing proactive dialogue systems in the era of LLMs <a href="./papers/proactive_prompt.pdf">[EMNLP'23a]</a>. To improve the proactiveness of conversational agents, we research on automatic ontology expansion <a href="./papers/clusterprompt.pdf">[EMNLP'23b,</a>  <a href="https://liziliao.github.io/papers/Semi_supervised.pdf">EMNLP'22a]</a>, target-driven conversational recommendation <a href="./papers/RTCP.pdf">[EMNLP'23c]</a> and building unified user simulators for better support <a href="https://liziliao.github.io/papers/User_Simulation.pdf">[EMNLP'22b]</a>. We also actively organize tutorials about proactive conversational agents <a href="https://liziliao.github.io/papers/WSDM2023_Tutorial.pdf">[WSDM'23,</a> <a href="https://dl.acm.org/doi/abs/10.1145/3539618.3594250">SIGIR'23]</a> to discuss important issues in conversational responses’ quality control, including safety, appropriateness, language detoxication, hallucination, and alignment.</p>


				</div>
				<!-- end boxed-->

				<div class="boxed">
					<p><a href="./files/pic_mcsr.png"><img border="1px" hspace="10" src="./files/pic_mcsr.png" style="float: left;" vspace="10" width="330px"></a>
					</p>

<h5 style="text-align: right"><strong>Multimodal Conversational Search and Recommendation</strong>
					</h5>


<p> Search and recommendation systems prevail and have profound impact. We aim to bridge the information asymmetry problem between the user and system via multimodal conversation <a href="http://staff.ustc.edu.cn/~hexn/papers/mm18-multimodal-dialog.pdf">[MM'18]</a>. It centers on broader types of ‘understand’ the user and ‘respond’ to the user under certain context. Specifically, we look into multimodal dialogue understanding <a href="https://arxiv.org/abs/2308.04502">[MM'23a]</a>, state tracking <a href="./papers/TMM_State.pdf">[TMM'22]</a>, knowledge-aware response generation <a href="./papers/Str2022.pdf">[SIGIR'22a]</a> and response strategy modeling <a href="https://liziliao.github.io/papers/Ref2022.pdf">[MM'22]</a>. </p>					
					
				</div>
				<!-- end boxed-->

				<div class="boxed">
					<p><a href="./files/pic_applications.png"><img border="1px" hspace="10" src="./files/pic_applications.png" style="float: right;" vspace="5" width="380px"></a>
					</p>

<h5><strong>Conversation AI + X (ChatPal, Learning Companion) Interdisciplinary Research</strong>
					</h5>


					<p> We work on a range of interesting and useful applications that aims to improve human life and society with conversational AI. A line of our research has focused on utilizing LLMs as "teachers" to enhance smaller models in various tasks such as emotional support <a href="https://arxiv.org/pdf/2308.11584.pdf">[arXiv'23, </a> <a href="https://arxiv.org/abs/2308.04502">MM'23a]</a>. We also recently started to develop question generation models for online learning companion. We also take a great interest in multimodal data, including work on human-in-the-loop video monent retrieval<a href="./papers/ACM_MM_2023_Weakly_VMR.pdf">[MM’23b]</a> and e-commerce data towards intelligent shopping assistant <a href="https://liziliao.github.io/papers/Learning_to_Ask.pdf">[SIGIR’22b]</a>. </p>



				</div>
				<!-- end boxed-->
			</div>
		</div>

		<!-- 
		<div class="content" id="advise">
			
			<h5 class="text-primary">CoAgent Lab</h5>
			
			<div class="projects" style="margin-left: 1em; margin-right: 1em">
				<div class="boxed">			
					<p><a href="./files/activities1.png"><img border="1px" hspace="5" vspace="4" src="./files/activities1.png" style="float: left;" width="400px"></a>
					</p>
					<p><a href="./files/activities2.png"><img border="1px" hspace="5" vspace="1" src="./files/activities2.png" style="float: right;" width="400px"></a>
					</p>
					<p><a href="./files/activities3.png"><img border="1px" hspace="5" vspace="4" src="./files/activities3.png" style="float: left;" width="400px"></a>
					</p>		

					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>
					<br>					
													
			</div></div>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Huy Quang Dao</a> (PhD, Spring 2024 -- ) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Jinggui Liang</a> (PhD, Summer 2023 -- ) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Mithun Subhash</a> (Undergrad, summer 2023 -- ) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Piranava Abeyakaran</a> (Undergrad, summer 2023 -- ) <br>
			
			<p>
			</p>
	 </div>
-->
		<div class="content">
			<h5 class="text-primary" id="publications">Preprints</h5>

			<ul>				
				<li>
					<a href="https://arxiv.org/pdf/2308.11584.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Building Emotional Support Chatbots in the Era of LLMs</a> <br>
					Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie
					<br>
					arXiv, 2023
				</li>	
								        				    
			</ul>
		</div>
				    
				    
		<div class="content">
			<h5 class="text-primary" id="publications">Publications</h5>

			<ul>
				<li>
					<a href="./papers/RTCP.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Harnessing Holistic Discourse Features and Triadic Interaction for Sentiment Quadruple Extraction in Dialogues</a> <br>
					Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Fangfang Su, Fei Li, Donghong Ji<br>
					AAAI, 2024<br>
				</li>

				<li>
					<a href="./papers/RTCP.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought</a> <br>
					Li Zheng, Hao Fei, Fei Li, Bobo Li, Lizi Liao, Donghong Ji, Chong Teng<br>
					AAAI, 2024<br>
				</li>

				<li>
					<a href="./papers/RTCP.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Reinforced Target-driven Conversational Promotion</a> <br>
					Huy Quang Dao, Lizi Liao, Dung D. Le, Yuxiang Nie<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="./papers/clusterprompt.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery</a> <br>
					Jinggui Liang, Lizi Liao<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="./papers/proactive_prompt.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Proactive Dialogue Systems in the Era of Large Language Models: Evaluating from a Prompting Perspective</a> <br>
					Yang Deng, Lizi Liao, Liang Chen, Hongru Wang, Wenqiang Lei, Tat-Seng Chua<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="./papers/emnlp23_survey.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions</a> <br>
					Libo Qin, Wenbo Pan, Qiguang Chen, Lizi Liao, Zhou Yu, Yue Zhang, Wanxiang Che, Min Li<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="https://arxiv.org/abs/2308.04502" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition</a> <br>
					Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Chong Teng, Tat-Seng Chua, Donghong Ji, Fei Li<br>
					ACM Multimedia, 2023<br>
				</li>


				<li>
					<a href="./papers/ACM_MM_2023_Weakly_VMR.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Partial Annotation-based Video Moment Retrieval via Iterative Learning</a> <br>
					Wei Ji, Renjie Liang, Lizi Liao, Hao Fei, Fuli Feng<br>
					ACM Multimedia, 2023<br>
				</li>


				<li>
					<a href="https://arxiv.org/pdf/2307.00968.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> REAL: A Representative Error-Driven Approach for Active Learning</a> [<a href="https://github.com/withchencheng/ECML_PKDD_23_Real">code & data</a>]<br>
					Cheng Chen, Yong Wang, Lizi Liao, Yueguo Chen, Xiaoyong Du<br>
					ECML/PKDD, 2023<br>
				</li>


				<li>
					<a href="https://liziliao.github.io/papers/SIGIR2023_Tutorial.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Proactive Conversational Agents in the Post-ChatGPT World</a><br>
					Lizi Liao, Grace Hui Yang, Chirag Shah<br>
					SIGIR, 2023<br>
				</li>


				<li>
					<a href="https://aclanthology.org/2023.findings-acl.849.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis</a> [<a href="https://github.com/unikcc/DiaASQ">code & data</a>]<br>
					Bobo Li, Hao Fei, Fei Li, Yuhan Wu, Jinsong Zhang, Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao, Tat-Seng Chua and Donghong Ji<br>
					ACL, 2023<br>
				</li>


				<li>
					<a href="https://liziliao.github.io/papers/Conversation_Disentanglement.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Conversation Disentanglement with Bi-Level Contrastive Learning</a><br>
					Chengyu Huang, Zheng Zhang, Hao Fei and Lizi Liao<br>
					EMNLP, 2022<br></li>


				<li>
					<a href="https://liziliao.github.io/papers/User_Simulation.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">A Unified Dialogue User Simulator for Few-shot Data Augmentation</a><br>
					Dazhen Wan, Zheng Zhang, Qi Zhu, Lizi Liao and Minlie Huang<br>
					EMNLP, 2022<br></li>

				<li>
					<a href="https://liziliao.github.io/papers/Semi_supervised.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Semi-supervised New Slot Discovery with Incremental Clustering</a><br>
					Yuxia Wu, Lizi Liao, Xueming Qian and Tat-Seng Chua<br>
					EMNLP, 2022<br></li>


				<li>
					<a href="https://liziliao.github.io/papers/Ref2022.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Reflecting on Experiences for Response Generation</a> [<a href="https://yecchen.github.io/paper/RERG_mm22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://files.atypon.com/acm/a90ccbfa09565d39924a1fe4f73dc94f">video</a>]<br>
					Chenchen Ye, Lizi Liao, Suyu Liu and Tat-Seng Chua<br>
					ACM Multimedia, 2022<br>
				</li>

				<li>
					<a href="./papers/Str2022.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Structured and Natural Responses Co-generation for Conversational Search</a> [<a href="https://yecchen.github.io/paper/Co-Gen_sigir22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3532063">video</a>, <a href="https://github.com/yecchen/Co-Gen">code & data</a>]<br>
					Chenchen Ye, Lizi Liao, Fuli Feng, Wei Ji and Tat-Seng Chua<br>
					SIGIR, 2022<br>
				</li>


				<li>
					<a href="./papers/Learning_to_Ask.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Learning to Ask Critical Questions for Assisting Product Search</a> [<a href="https://yecchen.github.io/paper/Co-Gen_sigir22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3532063">video</a>, <a href="https://github.com/yecchen/Co-Gen">code & data</a> ]<br>
					Zixuan Li, Lizi Liao and Tat-Seng Chua<br>
					SIGIR, 2022 (eCom) <br>
				</li>



				<li>
					<a href="./papers/TMM_State.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">State Graph Reasoning for Multimodal Conversational Recommendation</a><br>
					Yuxia Wu, Lizi Liao, Gangyi Zhang, Wenqiang Lei, Guoshuai Zhao, Xueming Qian, Tat-Seng Chua<br>
					TMM, 2022 <br>
				</li>


				<li>
					<a href="./papers/2021sigir_mmconv.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">MMConv: An Environment for Multimodal Conversational Search across Multiple Domains</a> [<a href="https://github.com/liziliao/MMConv">code & data</a>] <br>
					Lizi Liao, Le Hong Long, Zheng Zhang, Minlie Huang, Tat-Seng Chua<br>
					SIGIR, 2021<br>
				</li>


				<li>
					<a href="./papers/2021www_dst.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Multi-domain Dialogue State Tracking with Recursive Inference</a> [<a href="https://github.com/budzianowski/multiwoz/tree/master/data">data</a>]<br>
					Lizi Liao, Tongyao Zhu, Le Hong Long, Tat-Seng Chua<br>
					WWW , 2021<br>
				</li>


				<li>
					<a href="./papers/Enriching.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Towards Enriching Responses with Crowd-sourced Knowledge for Task-oriented Dialogue</a> [<a href="https://github.com/liziliao/MMConv">code & data</a>] <br>
					Yingxu He, Lizi Liao, Zheng Zhang, Tat-Seng Chua<br>
					ACM MM, 2021 (workshop) <br>
				</li>


				<li>
					<a href="./papers/DCR.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Topic-Guided Relational Conversational Recommender in Multiple Domains</a> [<a href="https://github.com/truthless11/DCR">code & data</a>]<br>
					Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang, Tat-Seng Chua<br>
					TKDE, 2020 <br>
				</li>


				<li>
					<a href="./papers/2020tacl_redst.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Dialogue State Tracking with Incremental Reasoning</a> [<a href="https://github.com/budzianowski/multiwoz/tree/master/data">data</a>]<br>
					Lizi Liao, Le Hong Long, Yunshan Ma, Wenqiang Lei, Tat-Seng Chua<br>
					TACL, 2020 <br>
				</li>


				<li>
					<a href="./papers/2019www_MultimediaDST_dialog.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems</a><br>
					Zheng Zhang, Lizi Liao, Minlie Huang, Xiaoyan Zhu, Tat-Seng Chua<br>
					WWW, 2019 <br>
				</li>


				<li>
					<a href="http://staff.ustc.edu.cn/~hexn/papers/mm18-multimodal-dialog.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Knowledge-aware Multimodal Dialogue Systems</a> <b style="color: green; background-color: #ffff42">(Best Paper Final List)</b> <br>
					Lizi Liao, Yunshan Ma, Xiangnan He, Richang Hong, Tat-Seng Chua<br>
					ACM Multimedia, 2018 <br>
				</li>


				<li>
					<a href="https://www.zhaobo.me/papers/mm_lizi.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Interpretable Multimodal Retrieval for Fashion Products</a><br>
					Lizi Liao, Xiangnan He, Bo Zhao, Chong-Wah Ngo, Tat-Seng Chua<br>
					ACM Multimedia, 2018 <br>
				</li>


				<li>
					<a href="https://arxiv.org/abs/1705.04969" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Attributed Social Network Embedding</a> [<a href="https://github.com/liziliao/ASNE">code & data</a>]<br>
					Lizi Liao, Xiangnan He, Hanwang Zhang, Tat-Seng Chua<br>
					TKDE, 2018<br>
				</li>


				<li>
					<a href="https://arxiv.org/abs/1708.05031" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Neural Collaborative Filtering</a> [<a href="https://github.com/liziliao/neural_collaborative_filtering">code & data</a>]<br>
					Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua<br>
					WWW, 2017<br>
				</li>
			</ul>
		</div>

		<div class="content" id="teach">
			<h5 class="text-primary">Teaching</h5>
			
			Current Offering:<br>
			<ul>
			<li><a href="https://liziliao.github.io/">Visual Analytics for Business Intelligence (IS428)</a> (undergraduate level - Spring 2024)</li>

			</ul>
			Previous Offerings:<br>
			<ul>
			<li><a href="https://liziliao.github.io/">Data Management (IS112)</a> (undergraduate level - Spring 2023)</li>	
			<li><a href="https://liziliao.github.io/">Visual Analytics for Business Intelligence (IS428)</a> (undergraduate level - Spring 2022, Spring 2023)</li>
			<li><a href="https://liziliao.github.io/">IS/SMT Project Experience (Applications) (IS483)</a> (undergraduate level - Spring 2022)</li>
			</ul>

			<p>
			</p>
		</div>		

		<div class="content">
			<h5 class="text-primary">Service</h5>

				Organizing Committee:<br>
				 <ul>
				 <li><a href="https://sigir-2024.github.io/">SIGIR 2024</a>, Doctoral Consortium Chair</li>
				 <li><a href="https://www2024.thewebconf.org/">The Web Conference 2024 (known as WWW)</a>, Local Arrangements Chair</li>
				 <li><a href="https://www.wsdm-conference.org/2023/">WSDM 2023</a>, Finance and Registration Chair</li>
				 <li><a href="http://tcci.ccf.org.cn/conference/2023/">NLPCC 2023</a>, Area Chair</li>
				 <li><a href="http://tcci.ccf.org.cn/conference/2022/">NLPCC 2022</a>, Area Chair</li> 
				 <li><a href="https://2019.acmmm.org/index.html">ACM Multimedia 2019</a>, Program design</li> 
				</ul>

				Senior Programe Committee Member: 
				<ul>
				 <li>International Joint Conference on Artificial Intelligence (IJCAI 2021)</li> 
				</ul>
		</div>
			
		<div class="content">
			<h5 class="text-primary">Miscellaneous</h5>


			<p>When I have spare time, I enjoy reading books, hiking, and dancing. </p>

			<p>
			</p>
		</div>
		Webpage template borrowed from Prof. <a href="https://cocoxu.github.io/#advise">Wei Xu</a>.

	
</body></html>