<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta content="IE=edge" http-equiv="X-UA-Compatible">
	<meta content="width=840, initial-scale=1.0" name="viewport">
	<meta content="Lizi Liao" name="author">
	<meta content="Homepage" name="description">

	<title>Lizi Liao - SMU - SCIS</title>
	<link rel="shortcut icon" href="https://www.ic.gatech.edu/sites/all/themes/coc_sub_theme/favicon.ico" type="image/vnd.microsoft.icon">
	<!-- Bootstrap core CSS -->
	<link href="./files/bootstrap.min.css" rel="stylesheet">
	<!-- Bootstrap theme -->
	<link href="./files/bootstrap-theme.min.css" rel="stylesheet">
	<!-- Bootstrap icon -->
	<link href="./files/bootstrap.icon-large.min.css" rel="stylesheet">
	<!-- Custom styles for this template -->
	<link href="./files/theme.css" rel="stylesheet">
	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<link rel="stylesheet" href="./files/font-awesome.min.css">

	<!--[if lt IE 9]>
	  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
	  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
	<![endif]-->
<script src="chrome-extension://njgehaondchbmjmajphnhlojfnbfokng/js/contentScripts/dom.js"></script></head>

<body>
   <script type="text/javascript" async="" src="./files/ga.js"></script>
	<div class="container-narrow">
		<div class="title">

			<h4><strong>Lizi Liao</strong> &nbsp;&nbsp;&nbsp;&nbsp; 
			
			<img class="img-thumbnail-lizi" height="300" hspace="10" src="./files/lizi_profile_image.jpg" style="float:right"> 
			
			</h4>
			Assistant Professor<br>
			Lee Kong Chian Fellow<br>
			<a href="https://scis.smu.edu.sg/">School of Computing and Information Systems</a> <br>
			<a href="https://www.smu.edu.sg/">Singapore Management University</a><br>
			<span class="glyphicon glyphicon-envelope"></span>&nbsp; <tt>lzliao at smu dot edu dot sg</tt><br>
			<b>Office: </b>SCIS2-4056<br>
			<a href="https://scholar.google.com.sg/citations?user=W2b08EUAAAAJ&hl=en">[Google Scholar]</a>

		    <br><br>
		    I am a faculty member of the <a href="https://scis.smu.edu.sg/">School of Computing and Information Systems</a> at <a href="https://www.smu.edu.sg/">SMU</a>. My research explores two questions: What are the underlying principles of humans understanding conversation context as well as making proper responses, and how we can implement them on machine learning models? Research on this topic has to necessarily be at the intersection of Machine Learning, Natural Language Processing and Multimedia. My group is specifically interested in task-oriented dialogues, proactive conversational agents, and multimodal conversational search and recommendation as the application target. I received my Ph.D. from NUS, advised by Professor <a href="https://scholar.google.com.sg/citations?user=Z9DWCBEAAAAJ&hl=zh-CN">Tat-Seng Chua</a>.
		    
		    <br>
			<br>
						
			<img src="./files/recruitment.png" width="20" alt="" style="border-style: none" align="center"> &nbsp; I'm recruiting 0-2 new PhD student(s) every intake batch (apply to <a href="https://scis.smu.edu.sg/phd/online-application">PhD</a> program and list me as a potential advisor). Our group also has multiple positions for summer interns and visiting research students. Please feel free to email me with your CV if you are interested. <br> 
			

		</div>

<div class="navbar navbar-default" role="navigation">
		
   		<div class="container">
        
				<div class="navbar-collapse">
				<ul class="nav navbar-nav">
					<li>
						<a href="https://liziliao.github.io/#research">Research</a>
					</li>

					<li>
						<a href="https://liziliao.github.io/#team">Team</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#publications">Publications</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#teach">Teaching</a>
					</li>


					<li>
						<a href="https://liziliao.github.io/#publications">Code &amp; Data</a>
					</li>
				</ul>

          
			</div>
		
		</div>
		</div>


		<div class="content">
			<h5 class="text-primary" id="news">What's New</h5>
		         
			<!-- <ul class="news"> -->
			<ul>
				<li style="list-style: none"><br>
				</li>

			<!-- <ul class="news"> -->
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Dec 2024], invited to serve as Asssociate Editor of <a href="https://dl.acm.org/journal/tois">TOIS</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Dec 2024], one paper accepted to AAAI 2025, to appear.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Nov 2024], invited to serve as Asssociate Editor of <a href="https://dl.acm.org/journal/tomm">TOMM</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Oct 2024], invited to give talk at <a href="https://aisps.github.io/">Visionary Symposium on Generative AI</a> organized by Tsinghua.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Sep 2024], six papers accepted to EMNLP 2024, to appear</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [May 2024], four papers accepted to ACL 2024: (1) <a href="https://liziliao.github.io/papers/ACL24_ChatPal.pdf">emotional support conversation</a>; (2) <a href="https://liziliao.github.io/papers/ACL24_planlikehuman.pdf">conversation planning</a>; (3) <a href="https://liziliao.github.io/papers/ACL24_TCE.pdf">temporal long context understanding</a>; (4) <a href="https://liziliao.github.io/papers/ACL24_SynCID.pdf">conversational intent discovery</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Apr 2024], check out our new IJCAI 2024 survey on <a href="https://liziliao.github.io/papers/A_Survey_on_Neural_Question_Generation.pdf">neural question generation</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Mar 2024], two papers accepted to SIGIR 2024: (1) <a href="https://liziliao.github.io/papers/SIGIR24_HPC.pdf">human-centered proactive conversational agents</a>; (2) <a href="https://liziliao.github.io/papers/DCRS_SIGIR24.pdf">conversational recommendation</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Mar 2024], three papers accepted to NAACL 2024: (1) <a href="https://liziliao.github.io/papers/NAACL_24_ALUP__Camera_Ready.pdf">new intent discovery</a>; (2) <a href="https://liziliao.github.io/papers/NAACL_24_Mix_Initiative_CRS__Camera_Ready.pdf">mix-initiative response generation</a>; (3) <a href="https://liziliao.github.io/papers/NAACL_2024_SGSH_Camera_ready.pdf">knowledge base question generation</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Feb 2024], check out our new The Web Conference paper on <a href="https://arxiv.org/pdf/2401.14009.pdf">transformer
for dynamic graph modeling</a>.</li>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jan 2024], received the <a href="https://research.google/outreach/featured-research-collaborations/"> Google South Asia & Southeast Asia research awards 2023</a>. </li>
			</ul>		
		</div>




		<div class="content">
			<h5 class="text-primary" id="research">Research Highlights</h5> 
			

			<div class="projects" style="margin-left: 1em; margin-right: 1em">
				<div class="boxed">
					<p><a href="./files/pic_proactive.png"><img border="1px" hspace="10" vspace="10" src="./files/pic_proactive.png" style="float: right;" width="330px"></a>
					</p>

<h5><strong>Proactive Conversational AI</strong>
					</h5>


<p> We recently published one of the earliest works on developing proactive dialogue systems in the era of LLMs <a href="./papers/proactive_prompt.pdf">[EMNLP'23a]</a>. To improve the proactiveness of conversational agents, we research on automatic ontology expansion <a href="./papers/clusterprompt.pdf">[EMNLP'23b,</a>  <a href="https://liziliao.github.io/papers/Semi_supervised.pdf">EMNLP'22a]</a>, target-driven conversational recommendation <a href="./papers/RTCP.pdf">[EMNLP'23c]</a> and building unified user simulators for better support <a href="https://liziliao.github.io/papers/User_Simulation.pdf">[EMNLP'22b]</a>. We also actively organize tutorials about proactive conversational agents <a href="https://liziliao.github.io/papers/WSDM2023_Tutorial.pdf">[WSDM'23,</a> <a href="https://dl.acm.org/doi/abs/10.1145/3539618.3594250">SIGIR'23]</a> to discuss important issues in conversational responses’ quality control, including safety, appropriateness, language detoxication, hallucination, and alignment.</p>


				</div>
				<!-- end boxed-->

				<div class="boxed">
					<p><a href="./files/pic_mcsr.png"><img border="1px" hspace="10" src="./files/pic_mcsr.png" style="float: left;" vspace="10" width="330px"></a>
					</p>

<h5 style="text-align: right"><strong>Multimodal Conversational Search and Recommendation</strong>
					</h5>


<p> Search and recommendation systems prevail and have profound impact. We aim to bridge the information asymmetry problem between the user and system via multimodal conversation <a href="http://staff.ustc.edu.cn/~hexn/papers/mm18-multimodal-dialog.pdf">[MM'18]</a>. It centers on broader types of ‘understand’ the user and ‘respond’ to the user under certain context. Specifically, we look into multimodal dialogue understanding <a href="https://arxiv.org/abs/2308.04502">[MM'23a]</a>, state tracking <a href="./papers/TMM_State.pdf">[TMM'22]</a>, knowledge-aware response generation <a href="./papers/Str2022.pdf">[SIGIR'22a]</a> and response strategy modeling <a href="https://liziliao.github.io/papers/Ref2022.pdf">[MM'22]</a>. </p>					
					
				</div>
				<!-- end boxed-->

				<div class="boxed">
					<p><a href="./files/pic_applications.png"><img border="1px" hspace="10" src="./files/pic_applications.png" style="float: right;" vspace="5" width="380px"></a>
					</p>

<h5><strong>Conversation AI + X (ChatPal, Learning Companion) Interdisciplinary Research</strong>
					</h5>


					<p> We work on a range of interesting and useful applications that aims to improve human life and society with conversational AI. A line of our research has focused on utilizing LLMs as "teachers" to enhance smaller models in various tasks such as emotional support <a href="https://arxiv.org/pdf/2308.11584.pdf">[arXiv'23, </a> <a href="https://arxiv.org/abs/2308.04502">MM'23a]</a>. We also recently started to develop question generation models for online learning companion. We also take a great interest in multimodal data, including work on human-in-the-loop video monent retrieval<a href="./papers/ACM_MM_2023_Weakly_VMR.pdf">[MM’23b]</a> and e-commerce data towards intelligent shopping assistant <a href="https://liziliao.github.io/papers/Learning_to_Ask.pdf">[SIGIR’22b]</a>. </p>



				</div>
				<!-- end boxed-->
			</div>
		</div>

		 
		<div class="content" id="team">
			
			<h5 class="text-primary">CoAgent Lab</h5>
			
			<!--<div class="projects" style="margin-left: 1em; margin-right: 1em">
				<div class="boxed">			
					<p><a href="./files/activities1.png"><img border="1px" hspace="5" vspace="4" src="./files/activities1.png" style="float: left;" width="400px"></a>
					</p>
					<p><a href="./files/activities2.png"><img border="1px" hspace="5" vspace="1" src="./files/activities2.png" style="float: right;" width="400px"></a>
					</p>
					<p><a href="./files/activities3.png"><img border="1px" hspace="5" vspace="4" src="./files/activities3.png" style="float: left;" width="400px"></a>
					</p>		

					<br>			
													
			</div></div>-->
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Jinggui Liang</a> (PhD student, SMU Presidential Doctoral Fellowship) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Huy Dao</a> (PhD student, SMU Presidential Doctoral Fellowship) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Zhihan Zhang</a> (PhD student, SCIS PhD Research Excellence Award) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Shuai Ling</a> (PhD student from HIT Shenzhen, co-supervise) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Zhengyang Liang</a> (PhD student) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Zailong Tian</a> (Research Engineer) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Xiaofeng Zhou </a> (Visiting Research student from Beijing Institute of Technology) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Kun Zhu </a> (Visiting Research student from Harbin Institute of Technology) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Bohan Li </a> (Visiting Research student from Harbin Institute of Technology) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Gia-Thinh Pham</a> (Visiting Research student from University of Science, VNU-HCM, coming soon) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Dang Hoang Minh Triet</a> (Visiting Research student from University of Science, VNU-HCM, coming soon) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Yi Han </a> (Visiting Research student from Harbin Institute of Technology, coming soon) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Junqiao Gong </a> (Visiting Research student from 
Hefei University of Technology, coming soon) <br>


			<h5 class="text-primary">Alumni</h5>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Yuqi Chu </a> (Visiting student from HFUT) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Tao He</a> (Visiting student from HIT) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Zhonghua Zheng</a> (Visiting student from HIT Shenzhen) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Suyu Liu</a> (Master student) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Shasha Guo</a> (Visiting student from RUC, now in ICT) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://liziliao.github.io/">Chengyu Huang </a> (Visiting student from NUS, now in NUS) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://tongyao-zhu.github.io/">Tongyao Zhu </a> (Visiting student from NUS, now in NUS) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://yecchen.github.io/">Chenchen Ye </a> (Visiting student from NUS, now in UCLA) <br>
			&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://yuxiawu.github.io/">Yuxia Wu </a> (Visiting student from XJTU, now in Huawei) <br>
			<p>
			</p>
	 </div>
				    
				    
		<div class="content">
			<h5 class="text-primary" id="publications">Publications</h5>

			<ul>
				<li>
					<a href="https://liziliao.github.io" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">DistillCaps: Enhancing Audio-Language Alignment in Captioning via Retrieval-Augmented Knowledge Distillation</a> <br>
					Thinh Pham, Nghiem Diep, Lizi Liao, Binh Nguyen<br>
					CIKM, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">MeMAD: Structured Memory of Debates for Enhanced Multi-Agent Reasoning</a> <br>
					Shuai Ling, Lizi Liao, Dongmei Jiang, Weili Guan<br>
					COLM, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Boosting Chart-to-Code Generation in MLLM via Dual Preference-Guided Refinement</a> <br>
					Zhihan Zhang, Yixin Cao, Lizi Liao<br>
					ACM Multimedia, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/Style_Transfer.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control</a> <br>
					Jinggui Liang, Dung Vo, Yap Hong Xian, Hai Leong Chieu, Kian Ming A. Chai, Jing Jiang, Lizi Liao<br>
					ACL, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/D_and_R.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement</a> <br>
					Xiaofeng Zhou, Heyan Huang, Lizi Liao<br>
					ACL Findings, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/XFinBench.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning</a> <br>
					Zhihan Zhang, Yixin Cao, Lizi Liao<br>
					ACL Findings, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Breaking the Reasoning Barrier A Survey on LLM Complex Reasoning through the Lens of Self-Evolution</a> <br>
					Tao He, Hao Li, Jingchang Chen, Runxuan Liu, Yixin Cao, Lizi Liao, Zihao Zheng, Zheng Chu, Jiafeng Liang, Ming Liu, Bing Qin<br>
					ACL Findings, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/MeMoTune.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">MeMoTune: A Measure and Moment-Driven Fine-Tuning Framework for Quantized Large Language Models</a> <br>
					Yun Zhang, Xue Geng, Lizi Liao, Jintong Sun, Minghe Yu, Ge Yu<br>
					ACL Findings, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">R2DQG: A Quality meets Diversity Framework for Question Generation over Knowledge Bases</a> <br>
					Yimeng Ren, Yanhua Yu, Lizi Liao, Yuhu Shang, Kangkang Lu, Mingliang Yan<br>
					IJCAI, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Dynamic Graph Modeling with Contextual and Temporal Relevance</a> <br>
					Yuxia Wu, Lizi Liao, Yuan Fang<br>
					SIGIR, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning</a> <br>
					Tao He, Lizi Liao, Ming Liu, Bing Qin<br>
					SIGIR, 2025<br>
				</li>
				<li>
					<a href="https://arxiv.org/abs/2502.04976" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark</a> <br>
					Han Zhang, Zixiang Meng, Meng Luo, Hong Han, Lizi Liao, Erik Cambria, Hao Fei<br>
					The Web Conference, 2025<br>
				</li>
				<li>
					<a href="https://arxiv.org/abs/2408.03650" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Towards Multimodal Emotional Support Conversation Systems</a> <br>
					Yuqi Chu, Lizi Liao, Zhiyuan Zhou, Chong-Wah Ngo, Richang Hong<br>
					TMM, 2025<br>
				</li>
				<li>
					<a href="https://dl.acm.org/doi/10.1145/3715097" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Proactive Conversational AI: A Comprehensive Survey of Advancements and Opportunities</a> <br>
					Yang Deng, Lizi Liao, Wenqiang Lei, Grace Yang, Wai Lam, Tat-Seng Chua<br>
					TOIS, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/AAAI_2025_Simulation.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues  (oral)</a> <br>
					Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Yiheng Sun, Zerui Chen, Ming Liu, Bing Qin<br>
					AAAI, 2025<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/Survey_OnExpan_EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">A Survey of Ontology Expansion for Conversational Understanding</a> <br>
					Jinggui Liang, Yuxia Wu, Yuan Fang, Hao Fei, Lizi Liao<br>
					EMNLP, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/Thoughts_to_Target__EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Thoughts to Target: Enhance Planning for Target-driven Conversation</a> <br>
					Zhonghua Zheng, Lizi Liao, Yang Deng, Ee-Peng Lim, Minlie Huang, Liqiang Nie<br>
					EMNLP, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/multi_intentSLU_EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding</a> <br>
					Bowen Xing, Lizi Liao, Minlie Huang, Ivor Tsang<br>
					EMNLP, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/PCQPR_EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">PCQPR: Proactive Conversational Question Planning with Reflection</a> <br>
					Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen<br>
					EMNLP, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/TEPL_EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues</a> <br>
					Huy Dao, Yang Deng, Khanh-Huyen Bui, Dung D. Le, Lizi Liao<br>
					EMNLP Findings, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/VCU_EMNLP24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Balancing Visual Context Understanding in Dialogue for Image Retrieval</a> <br>
					Zhaohui Wei, Lizi Liao, Xiaoyu Du, Xinguang Xiang<br>
					EMNLP Findings, 2024<br>
				</li>
				<li>
					<a href="https://dl.acm.org/doi/10.1145/3698191" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Revisiting Conversation Discourse for Dialogue Disentanglement</a> <br>
					Bobo Li, Hao Fei, Fei Li, Shengqiong Wu, Lizi Liao, Yinwei Wei, Tat-seng Chua, Donghong Ji<br>
					TOIS, 2024<br>
				</li>
				<li>
					<a href="https://openreview.net/pdf?id=BlttBoaYVu" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Self-Adaptive Fine-grained Multi-modal Data Augmentation for Semi-supervised Muti-modal Coreference Resolution</a> <br>
					Li Zheng, Boyu Chen, Hao Fei, Fei Li, Shengqiong Wu, Lizi Liao, Donghong Ji, Chong Teng<br>
					ACM MM, 2024<br>
				</li>

				<li>
					<a href="https://liziliao.github.io/papers/ACL24_empathyear.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">EmpathyEar: An Open-source Avatar Multimodal Empathetic Chatbot</a> <br>
					Hao Fei, Han Zhang, Bin Wang, Lizi Liao, Qian Liu, Erik Cambria<br>
					ACL demo, 2024<br>
				</li>

				<li>
					<a href="https://liziliao.github.io/papers/ACL24_planlikehuman.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Planning Like Human: A Dual-process Framework for Dialogue Planning</a> <br>
					Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Ming Liu, Zerui Chen, Bing Qin<br>
					ACL, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/ACL24_ChatPal.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Self-chats from Large Language Models Make Small ChatPal Better</a> <br>
					Zhonghua Zheng, Lizi Liao, Yang Deng, Libo Qin, Liqiang Nie<br>
					ACL, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/ACL24_TCE.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding</a> <br>
					Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, Tat-Seng Chua<br>
					ACL, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/ACL24_SynCID.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Synergizing Large Language Models and Pre-Trained Smaller Models for Conversational Intent Discovery</a> <br>
					Jinggui Liang, Lizi Liao, Hao Fei, Jing Jiang<br>
					ACL Findings, 2024<br>
				</li>

				<li>
					<a href="https://liziliao.github.io/papers/A_Survey_on_Neural_Question_Generation.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> A Survey on Neural Question Generation: Methods, Applications, and Prospects</a> <br>
					Shasha Guo, Lizi Liao, Cuiping Li, Tat-Seng Chua<br>
					IJCAI, 2024<br>
				</li>

				<li>
					<a href="https://liziliao.github.io/papers/SIGIR24_HPC.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Towards Human-centered Proactive Conversational Agents</a> <br>
					Yang Deng, Lizi Liao, Zhonghua Zheng, Grace Hui Yang, Tat-Seng Chua<br>
					SIGIR, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/DCRS_SIGIR24.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Broadening the View: Demonstration-augmented Prompt Learning for Conversational Recommendation</a> <br>
					Huy Dao, Yang Deng, Dung Le, Lizi Liao<br>
					SIGIR, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/NAACL_24_ALUP__Camera_Ready.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery</a> <br>
					Jinggui Liang, Lizi Liao, Hao Fei, Bobo Li, Jing Jiang<br>
					NAACL, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/NAACL_24_Mix_Initiative_CRS__Camera_Ready.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Mix-Initiative Response Generation with Dynamic Prefix Tuning</a> <br>
					Yuxiang Nie, Heyan Huang, Xian-Ling Mao, Lizi Liao<br>
					NAACL, 2024<br>
				</li>
				<li>
					<a href="https://liziliao.github.io/papers/NAACL_2024_SGSH_Camera_ready.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation</a> <br>
					Shasha Guo, Lizi Liao, Jing Zhang, Yanling Wang, Cuiping Li, Hong Chen<br>
					NAACL Findings, 2024<br>
				</li>
				<li>
					<a href="https://arxiv.org/pdf/2401.14009.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> On the Feasibility of Simple Transformer for Dynamic Graph Modeling</a> <br>
					Yuxia Wu, Yuan Fang, Lizi Liao<br>
					The Web Conference, 2024<br>
				</li>

				<li>
					<a href="./papers/Actively_Discovering_New_Slots_for_Task_oriented_Conversation.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Actively Discovering New Slots for Task-oriented Conversation</a> <br>
					Yuxia Wu, Tianhao Dai, Zedong Zheng, Lizi Liao<br>
					TASLP, 2024<br>
				</li>

				<li>
					<a href="./papers/AAAI24_Harnessing.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Harnessing Holistic Discourse Features and Triadic Interaction for Sentiment Quadruple Extraction in Dialogues</a> <br>
					Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Fangfang Su, Fei Li, Donghong Ji<br>
					AAAI, 2024<br>
				</li>

				<li>
					<a href="./papers/AAAI24_Reverse.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought</a> <br>
					Li Zheng, Hao Fei, Fei Li, Bobo Li, Lizi Liao, Donghong Ji, Chong Teng<br>
					AAAI, 2024<br>
				</li>

				<li>
					<a href="./papers/RTCP.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Reinforced Target-driven Conversational Promotion</a> <br>
					Huy Dao, Lizi Liao, Dung D. Le, Yuxiang Nie<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="./papers/clusterprompt.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery</a> <br>
					Jinggui Liang, Lizi Liao<br>
					EMNLP Findings, 2023<br>
				</li>

				<li>
					<a href="./papers/proactive_prompt.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Proactive Dialogue Systems in the Era of Large Language Models: Evaluating from a Prompting Perspective</a> <br>
					Yang Deng, Lizi Liao, Liang Chen, Hongru Wang, Wenqiang Lei, Tat-Seng Chua<br>
					EMNLP Findings, 2023<br>
				</li>

				<li>
					<a href="./papers/emnlp23_survey.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions</a> <br>
					Libo Qin, Wenbo Pan, Qiguang Chen, Lizi Liao, Zhou Yu, Yue Zhang, Wanxiang Che, Min Li<br>
					EMNLP, 2023<br>
				</li>

				<li>
					<a href="https://arxiv.org/abs/2308.04502" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition</a> <br>
					Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Chong Teng, Tat-Seng Chua, Donghong Ji, Fei Li<br>
					ACM Multimedia, 2023<br>
				</li>


				<li>
					<a href="./papers/ACM_MM_2023_Weakly_VMR.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Partial Annotation-based Video Moment Retrieval via Iterative Learning</a> <br>
					Wei Ji, Renjie Liang, Lizi Liao, Hao Fei, Fuli Feng<br>
					ACM Multimedia, 2023<br>
				</li>


				<li>
					<a href="https://arxiv.org/pdf/2307.00968.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> REAL: A Representative Error-Driven Approach for Active Learning</a> [<a href="https://github.com/withchencheng/ECML_PKDD_23_Real">code & data</a>]<br>
					Cheng Chen, Yong Wang, Lizi Liao, Yueguo Chen, Xiaoyong Du<br>
					ECML/PKDD, 2023<br>
				</li>


				<li>
					<a href="https://liziliao.github.io/papers/SIGIR2023_Tutorial.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Proactive Conversational Agents in the Post-ChatGPT World</a><br>
					Lizi Liao, Grace Hui Yang, Chirag Shah<br>
					SIGIR Tutorial, 2023<br>
				</li>


				<li>
					<a href="https://aclanthology.org/2023.findings-acl.849.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis</a> [<a href="https://github.com/unikcc/DiaASQ">code & data</a>]<br>
					Bobo Li, Hao Fei, Fei Li, Yuhan Wu, Jinsong Zhang, Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao, Tat-Seng Chua and Donghong Ji<br>
					ACL Findings, 2023<br>
				</li>


				<li>
					<a href="https://liziliao.github.io/papers/Conversation_Disentanglement.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none"> Conversation Disentanglement with Bi-Level Contrastive Learning</a><br>
					Chengyu Huang, Zheng Zhang, Hao Fei and Lizi Liao<br>
					EMNLP Findings, 2022<br></li>


				<li>
					<a href="https://liziliao.github.io/papers/User_Simulation.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">A Unified Dialogue User Simulator for Few-shot Data Augmentation</a><br>
					Dazhen Wan, Zheng Zhang, Qi Zhu, Lizi Liao and Minlie Huang<br>
					EMNLP Findings, 2022<br></li>

				<li>
					<a href="https://liziliao.github.io/papers/Semi_supervised.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Semi-supervised New Slot Discovery with Incremental Clustering</a><br>
					Yuxia Wu, Lizi Liao, Xueming Qian and Tat-Seng Chua<br>
					EMNLP Findings, 2022<br></li>


				<li>
					<a href="https://liziliao.github.io/papers/Ref2022.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Reflecting on Experiences for Response Generation</a> [<a href="https://yecchen.github.io/paper/RERG_mm22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://files.atypon.com/acm/a90ccbfa09565d39924a1fe4f73dc94f">video</a>]<br>
					Chenchen Ye, Lizi Liao, Suyu Liu and Tat-Seng Chua<br>
					ACM Multimedia, 2022<br>
				</li>

				<li>
					<a href="./papers/Str2022.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Structured and Natural Responses Co-generation for Conversational Search</a> [<a href="https://yecchen.github.io/paper/Co-Gen_sigir22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3532063">video</a>, <a href="https://github.com/yecchen/Co-Gen">code & data</a>]<br>
					Chenchen Ye, Lizi Liao, Fuli Feng, Wei Ji and Tat-Seng Chua<br>
					SIGIR, 2022<br>
				</li>


				<li>
					<a href="./papers/Learning_to_Ask.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Learning to Ask Critical Questions for Assisting Product Search</a> [<a href="https://yecchen.github.io/paper/Co-Gen_sigir22_slides.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">slides</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3532063">video</a>, <a href="https://github.com/yecchen/Co-Gen">code & data</a> ]<br>
					Zixuan Li, Lizi Liao and Tat-Seng Chua<br>
					SIGIR, 2022 (eCom) <br>
				</li>



				<li>
					<a href="./papers/TMM_State.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">State Graph Reasoning for Multimodal Conversational Recommendation</a><br>
					Yuxia Wu, Lizi Liao, Gangyi Zhang, Wenqiang Lei, Guoshuai Zhao, Xueming Qian, Tat-Seng Chua<br>
					TMM, 2022 <br>
				</li>


				<li>
					<a href="./papers/2021sigir_mmconv.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">MMConv: An Environment for Multimodal Conversational Search across Multiple Domains</a> [<a href="https://github.com/liziliao/MMConv">code & data</a>] <br>
					Lizi Liao, Le Hong Long, Zheng Zhang, Minlie Huang, Tat-Seng Chua<br>
					SIGIR, 2021<br>
				</li>


				<li>
					<a href="./papers/2021www_dst.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Multi-domain Dialogue State Tracking with Recursive Inference</a> [<a href="https://github.com/budzianowski/multiwoz/tree/master/data">data</a>]<br>
					Lizi Liao, Tongyao Zhu, Le Hong Long, Tat-Seng Chua<br>
					WWW , 2021<br>
				</li>


				<li>
					<a href="./papers/Enriching.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Towards Enriching Responses with Crowd-sourced Knowledge for Task-oriented Dialogue</a> [<a href="https://github.com/liziliao/MMConv">code & data</a>] <br>
					Yingxu He, Lizi Liao, Zheng Zhang, Tat-Seng Chua<br>
					ACM MM, 2021 (workshop) <br>
				</li>


				<li>
					<a href="./papers/DCR.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Topic-Guided Relational Conversational Recommender in Multiple Domains</a> [<a href="https://github.com/truthless11/DCR">code & data</a>]<br>
					Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang, Tat-Seng Chua<br>
					TKDE, 2020 <br>
				</li>


				<li>
					<a href="./papers/2020tacl_redst.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Dialogue State Tracking with Incremental Reasoning</a> [<a href="https://github.com/budzianowski/multiwoz/tree/master/data">data</a>]<br>
					Lizi Liao, Le Hong Long, Yunshan Ma, Wenqiang Lei, Tat-Seng Chua<br>
					TACL, 2020 <br>
				</li>


				<li>
					<a href="./papers/2019www_MultimediaDST_dialog.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems</a><br>
					Zheng Zhang, Lizi Liao, Minlie Huang, Xiaoyan Zhu, Tat-Seng Chua<br>
					WWW, 2019 <br>
				</li>


				<li>
					<a href="http://staff.ustc.edu.cn/~hexn/papers/mm18-multimodal-dialog.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Knowledge-aware Multimodal Dialogue Systems</a> <b style="color: green; background-color: #ffff42">(Best Paper Final List)</b> <br>
					Lizi Liao, Yunshan Ma, Xiangnan He, Richang Hong, Tat-Seng Chua<br>
					ACM Multimedia, 2018 <br>
				</li>


				<li>
					<a href="https://www.zhaobo.me/papers/mm_lizi.pdf" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Interpretable Multimodal Retrieval for Fashion Products</a><br>
					Lizi Liao, Xiangnan He, Bo Zhao, Chong-Wah Ngo, Tat-Seng Chua<br>
					ACM Multimedia, 2018 <br>
				</li>


				<li>
					<a href="https://arxiv.org/abs/1705.04969" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Attributed Social Network Embedding</a> [<a href="https://github.com/liziliao/ASNE">code & data</a>]<br>
					Lizi Liao, Xiangnan He, Hanwang Zhang, Tat-Seng Chua<br>
					TKDE, 2018<br>
				</li>


				<li>
					<a href="https://arxiv.org/abs/1708.05031" id="smt-simple" name="smt-simple" style="font-style: italic; text-decoration: none">Neural Collaborative Filtering</a> [<a href="https://github.com/liziliao/neural_collaborative_filtering">code & data</a>]<br>
					Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua<br>
					WWW, 2017<br>
				</li>
			</ul>
		</div>

		<div class="content" id="teach">
			<h5 class="text-primary">Teaching</h5>
			
			Current Offering:<br>
			<ul>
			<li><a href="https://liziliao.github.io/">Visual Analytics for Business Intelligence (IS428)</a> (undergraduate level - Autumn 2024)</li>
			<li><a href="https://liziliao.github.io/">Text Analytics and Application (ISSS609)</a> (graduate level - Autumn 2024)</li>
			 

			</ul>
			Previous Offerings:<br>
			<ul>
			<li><a href="https://liziliao.github.io/">Data Management (IS112)</a> (undergraduate level - Spring 2023)</li>	
			<li><a href="https://liziliao.github.io/">Visual Analytics for Business Intelligence (IS428)</a> (undergraduate level - Spring 2022, Spring 2023, Spring 2024)</li>
			<li><a href="https://liziliao.github.io/">IS/SMT Project Experience (Applications) (IS483)</a> (undergraduate level - Spring 2022)</li>
			</ul>

			<p>
			</p>
		</div>		

		<div class="content">
			<h5 class="text-primary">Service</h5>

				Organizing Committee:<br>
				 <ul>
				 <li><a href="https://sigir-2024.github.io/">ACL, EMNLP, NAACL, COLING 2024</a>, Area Chair</li>
				 <li><a href="https://sigir-2024.github.io/">SIGIR 2024</a>, Doctoral Consortium Chair</li>
				 <li><a href="https://www2024.thewebconf.org/">The Web Conference 2024 (known as WWW)</a>, Local Arrangements Chair</li>
				 <li><a href="https://www.wsdm-conference.org/2023/">WSDM 2023</a>, Finance and Registration Chair</li>
				 <li><a href="http://tcci.ccf.org.cn/conference/2023/">NLPCC 2022, 2023</a>, Area Chair</li>
				 <li><a href="https://2019.acmmm.org/index.html">ACM Multimedia 2019</a>, Program design</li> 
				</ul>

				Senior Programe Committee Member: 
				<ul>
				 <li>International Joint Conference on Artificial Intelligence (IJCAI 2021)</li> 
				</ul>
		</div>
			
		<div class="content">
			<h5 class="text-primary">Miscellaneous</h5>


			<p>When I have spare time, I enjoy reading books, hiking, and dancing. </p>

			<p>
			</p>
		</div>
		Webpage template borrowed from Prof. <a href="https://cocoxu.github.io/#advise">Wei Xu</a>.

	
</body></html>